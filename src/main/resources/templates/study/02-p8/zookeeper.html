<!doctype html>
<html lang="zh-CN">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="initial-scale=1.0, user-scalable=no, width=device-width">
    <title>zookeeper</title>

    <link rel="stylesheet" href="../00-static/base.css">
    <style>

    </style>

    <script src="../00-static/base.js"></script>

</head>
<body>

<pre>

    <h2 class="anchor">概念</h2>
    官网 zookeeper.apache.org
    引入
        leader挂了, 服务不可用, 不可靠,
        事实 zk集群极其高可用
        若有一种方式可以快速恢复出一个leader
    模型 --简单的主从
        只有一个主节点
        所有发生在从节点的写操作都会转给主节点 然后按顺序执行
    两种状态
        可用 有主
        不可用 无主
        不可用恢复到可用应该越快越好 官方压测200ms
    目录树结构
        节点 可以存数据 官方限制1M 不要当做数据库用 为了达到高性能
            持久节点
            临时节点 --客户端连接到zookeeper会产生一个session(创建 销毁)
                create -e ***
        序列节点(逻辑) --持久节点和临时节点可以带序列号
            create -s ***
        功能
            1 统一配置管理 节点1M数据
            2 分组管理 path结构,类似文件目录系统
            3 同一命名 sequential
            4 同步 临时节点
    特征/保障
        顺序一致性: 客户端接收消息 事务是按顺序排列的
        原子性: 更新(同步到其他节点, 最终一致性 一半成功)要么成功 要么失败
        统一试图: 无论连哪个节点 看到的视图都一样
        可靠性: 持久化 写日志
        及时性: 最终一致性
            若访问的从节点还没有同步完成,调用一个命令,去主节点同步(很短的时间就可完成)
            然后发给调用者最新的(集群一致的)结果
    实现: client
        分布式锁: 临时节点
            用session当做判断依据,挂了或执行完了删除session锁
            父节点下可以有多把锁(-s)
            队列式 事物的 锁
        HA 选主

    <h2 class="anchor">安装</h2>
    官网wget下载 解压
    添加到PATH --/zk/bin
    zoo.cfg --默认启动加载配置文件
        tickTime=2000 --心跳时间 确保从活着
        initLimit=10 --心跳*10 初始化连接 超出时间丢弃节点
        syncLimit=5 --心跳*5 主节点有同步等操作 超出时间认为有问题
        dataDir= --持久化目录 /var/apache/zppkeeper
            放一个文件 myid --内容为下四个节点中本机节点的号 例如 1
        # 4个节点 靠人规划zookeeper集群
        # =节点:若选为leader此端口起leader:没有leader,从这个端口通信 过半谦让选leader
        server.1=node01:2888:3888
        server.2=node02:2888:3888
        server.3=node03:2888:3888
        server.4=node04:2888:3888
    启动 zkServer.sh help/start(后台)/start-foreground(前台)/...
    集群配置
        所有节点相同的配置文件 不同的myid

    注意 在linux中 需要防火墙开启端口才能实现集群之间的相互通信

    <h2 class="anchor">使用</h2>
    二进制安全的
    连接 zlCli.sh
    创建节点
        create /folder "" --不加数据不能创建节点
        create -s /folder "" --多人创建同一节点会变成序列节点,可以规避被覆盖问题
    获得节点数据 get -s /folder
        cZxid = 0x200000002 --创建
            顺序执行,leader单机维护递增器
            0x 2(32位-开头0省略 leader纪元,第几个,重新选举会+1) 00000002(事务id号,同mZxid用一个顺序)
        mZxid = 0x200000004 --修改
            0x 2 00000004(事务id号)
        pZxid = 0x200000004 --本节点下 创建最后一个子节点时的事务id号
        ephemeralOwner = 0X0 --临时节点 sessionid
            伴随session会话期 会话结束删除
            如果服务端挂了 连其他服务端用同一sessionid仍可以连接并拿到数据
            创建的时候会统一视图,消耗一个事务id同步sessionid
            create -e /n01

    <h2 class="anchor">节点间的socket连接</h2>
    2888 --leader接收写请求 同步数据
    3888 --选主投票
    netstat -natp | egrep '(2888|3888)'
        tcp6 0 0 192.168.1.161:3888  :::*                LISTEN      2939/java
        tcp6 0 0 192.168.1.161:3888  192.168.1.163:48270 ESTABLISHED 2939/java
        tcp6 0 0 192.168.1.161:3888  192.168.1.162:34232 ESTABLISHED 2939/java
        tcp6 0 0 192.168.1.161:52108 192.168.1.163:2888  ESTABLISHED 2939/java
        tcp6 0 0 192.168.1.161:3888  192.168.1.164:43880 ESTABLISHED 2939/java
        说明
            1行 自己监听3888
            2/3/5行 自己的3888被其他连接
            4行 连接主节点

    <h2 class="anchor">...</h2>

</pre>

</body>
</html>